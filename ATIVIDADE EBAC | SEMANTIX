# PROJETO SEMANTIX - ANÁLISE DE PACIENTES


# --- 1. Importar bibliotecas ---
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

sns.set(style="whitegrid")

# --- 2. Carregar dados ---
df = pd.read_csv('/content/patients.csv')

# Visualização inicial
print("Dimensões da base:", df.shape)
print("Primeiras linhas:")
display(df.head())
print("Informações gerais:")
df.info()
print("Estatísticas descritivas:")
display(df.describe())

# --- 3. Pré-processamento ---
# Transformar datas em datetime
df['arrival_date'] = pd.to_datetime(df['arrival_date'])
df['departure_date'] = pd.to_datetime(df['departure_date'])

# Criar coluna de duração da estadia
df['stay_duration'] = (df['departure_date'] - df['arrival_date']).dt.days

# Codificar colunas categóricas
le_service = LabelEncoder()
df['service_encoded'] = le_service.fit_transform(df['service'])

le_name = LabelEncoder()
df['name_encoded'] = le_name.fit_transform(df['name'])

# Tratar valores faltantes
df.fillna({'satisfaction': df['satisfaction'].median()}, inplace=True)

# --- 4. Visualização inicial de dados ---
# Distribuição de idades
plt.figure(figsize=(10,5))
sns.histplot(df['age'], bins=20, kde=True, color='skyblue')
plt.title('Distribuição de Idades dos Pacientes')
plt.xlabel('Idade')
plt.ylabel('Quantidade')
plt.show()

# Satisfação por serviço
plt.figure(figsize=(12,6))
sns.boxplot(x='service', y='satisfaction', data=df)
plt.title('Satisfação por Serviço')
plt.xticks(rotation=45)
plt.show()

# Scatter interativo de duração da estadia x satisfação
fig = px.scatter(df, x='stay_duration', y='satisfaction', color='service',
                 hover_data=['name', 'age'], title='Duração da estadia vs Satisfação')
fig.show()

# --- 5. PCA para reduzir dimensionalidade ---
features = ['age', 'stay_duration', 'service_encoded', 'name_encoded']
X = df[features]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

df['pca1'] = X_pca[:,0]
df['pca2'] = X_pca[:,1]

# Gráfico PCA
plt.figure(figsize=(10,6))
sns.scatterplot(x='pca1', y='pca2', hue='service', data=df, palette='Set2')
plt.title('PCA - Redução para 2 dimensões')
plt.show()

# --- 6. K-Means Clustering ---
kmeans = KMeans(n_clusters=3, random_state=42)
df['cluster'] = kmeans.fit_predict(X_scaled)

# Visualizar clusters no PCA
plt.figure(figsize=(10,6))
sns.scatterplot(x='pca1', y='pca2', hue='cluster', palette='Set1', data=df)
plt.title('Clusters de Pacientes (K-Means)')
plt.show()

# --- 7. Modelo de Regressão (Random Forest) ---
y = df['satisfaction']
X_model = df[['age', 'stay_duration', 'service_encoded']]

X_train, X_test, y_train, y_test = train_test_split(X_model, y, test_size=0.3, random_state=42)

rf = RandomForestRegressor(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)

# Avaliação do modelo
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"Random Forest Regressor - RMSE: {rmse:.2f}, R²: {r2:.2f}")

# Feature importance
feat_importance = pd.DataFrame({'Feature': X_model.columns, 'Importance': rf.feature_importances_})
feat_importance = feat_importance.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(8,5))
sns.barplot(x='Importance', y='Feature', data=feat_importance, palette='viridis')
plt.title('Importância das Features - Random Forest')
plt.show()

# --- 8. Conclusões preliminares ---
print("Clusters formados:", df['cluster'].unique())
print("Features mais importantes para satisfação:", feat_importance)
